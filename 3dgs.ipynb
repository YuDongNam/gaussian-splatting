{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1OlN_5NWWXq"
      },
      "source": [
        "# ìµœì´ˆ ë°ì´í„° ì¤€ë¹„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VL3T_uiMXHC",
        "outputId": "72ef23aa-35e2-4cea-9367-7428d6d28188"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeJ729BhFCJw",
        "outputId": "0a2bc8ef-8d87-4855-868d-3f7596671a6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-11-24 10:11:23--  http://storage.googleapis.com/gresearch/refraw360/360_v2.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.174.207, 74.125.23.207, 74.125.203.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.174.207|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12535427936 (12G) [application/zip]\n",
            "Saving to: â€˜/content/drive/MyDrive/3dgs/360_v2.zipâ€™\n",
            "\n",
            "360_v2.zip          100%[===================>]  11.67G  30.0MB/s    in 7m 8s   \n",
            "\n",
            "2025-11-24 10:18:32 (27.9 MB/s) - â€˜/content/drive/MyDrive/3dgs/360_v2.zipâ€™ saved [12535427936/12535427936]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Mip-NeRF 360 ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ (ì•½ 4~5GB)\n",
        "!wget http://storage.googleapis.com/gresearch/refraw360/360_v2.zip -P /content/drive/MyDrive/3dgs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLK3rc7vP4rE"
      },
      "source": [
        "# í´ë¡  ë° ì˜ì¡´ì„± ì„¤ì¹˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsuA3TSQMEKq"
      },
      "outputs": [],
      "source": [
        "# 1. êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸ (ë°ì´í„° ë° ê²°ê³¼ ì €ì¥ìš©)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqXAgLimWf35"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 3. ê¹ƒí—ˆë¸Œ ë ˆí¬ í´ë¡  (ì‚¬ìš©ìë‹˜ ë ˆí¬)\n",
        "# ì´ë¯¸ í´ë¡ ë˜ì–´ ìˆë‹¤ë©´ pullë§Œ í•˜ê±°ë‚˜ ë„˜ì–´ê°‘ë‹ˆë‹¤.\n",
        "if not os.path.exists(\"gaussian-splatting\"):\n",
        "    !git clone --recursive https://github.com/YuDongNam/gaussian-splatting.git\n",
        "\n",
        "%cd gaussian-splatting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UolbffgWik5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 4. ì˜ì¡´ì„± ì„¤ì¹˜ ë° ì„œë¸Œëª¨ë“ˆ ì»´íŒŒì¼ (ì•½ 3~5ë¶„ ì†Œìš”)\n",
        "# ì£¼ì˜: ì½”ë© GPUì— ë§ì¶° ì»´íŒŒì¼í•˜ë¯€ë¡œ ì‹œê°„ì´ ì¢€ ê±¸ë¦½ë‹ˆë‹¤.\n",
        "!pip install -q plyfile\n",
        "!pip install -r requirements.txt\n",
        "!pip install submodules/diff-gaussian-rasterization\n",
        "!pip install submodules/simple-knn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L4fN4EEYWP6"
      },
      "source": [
        "# ë°ì´í„° ì¤€ë¹„(from gdrive to local)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0nQ9h7qfcmP"
      },
      "outputs": [],
      "source": [
        "# Colabì—ì„œ ì˜ˆì‹œ\n",
        "from src.config import CFG\n",
        "\n",
        "cfg = CFG()  # ì´ ì‹œì ì— ëª¨ë“  í´ë”ê°€ ìë™ ìƒì„±ë¨!\n",
        "# data/, data/ckpts/, data/tables/, outputs/ ëª¨ë‘ ìƒì„±ë¨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdPEJvLmfmYZ"
      },
      "source": [
        "## 1. Mip-NeRF 360 (6ê°œ ì¥ë©´: bonsai, counter, bicycle, garden, stump, kitchen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dS1fnjfAYVzo"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "\n",
        "# 1. ë§í¬ì—ì„œ 'd/' ì™€ '/view' ì‚¬ì´ì— ìˆëŠ” íŒŒì¼ IDë§Œ ì¶”ì¶œ\n",
        "file_id = \"1lNQKolRBe3bHV2mz7uKcWtG0rB8vGABI\"\n",
        "\n",
        "# 2. ë‹¤ìš´ë¡œë“œìš© URL í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "\n",
        "# 3. ë‹¤ìš´ë¡œë“œ ì‹¤í–‰ (outputì€ ì €ì¥í•  íŒŒì¼ëª…, ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ì›ë³¸ ì´ë¦„ ì‚¬ìš©)\n",
        "gdown.download(url, output=\"360v2.zip\", quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ik_ZIEP0cYjw"
      },
      "outputs": [],
      "source": [
        "# data/scenes í´ë” ìƒì„± (ì—†ìœ¼ë©´ ìë™ ìƒì„±)\n",
        "import os\n",
        "os.makedirs(\"data/scenes\", exist_ok=True)\n",
        "\n",
        "# ì••ì¶• í•´ì œ (scenes í´ë” ì•ˆì—)\n",
        "!unzip 360v2.zip -d data/scenes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S55_igTrf_FO"
      },
      "source": [
        "## 2. truck and temples (2ê°œ ì¥ë©´: train, truck)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMWyvJOFgnJq"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "\n",
        "# 1. ë§í¬ì—ì„œ 'd/' ì™€ '/view' ì‚¬ì´ì— ìˆëŠ” íŒŒì¼ IDë§Œ ì¶”ì¶œ\n",
        "file_id = \"1MBn36eONnqHCPj0aeM34zh4t74TM2ZXw\"\n",
        "\n",
        "# 2. ë‹¤ìš´ë¡œë“œìš© URL í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "\n",
        "# 3. ë‹¤ìš´ë¡œë“œ ì‹¤í–‰ (outputì€ ì €ì¥í•  íŒŒì¼ëª…, ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ì›ë³¸ ì´ë¦„ ì‚¬ìš©)\n",
        "gdown.download(url, output=\"traintruck.zip\", quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmu0IVrDge7w"
      },
      "outputs": [],
      "source": [
        "# data/scenes í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±\n",
        "import os\n",
        "os.makedirs(\"data/scenes\", exist_ok=True)\n",
        "\n",
        "# ì••ì¶• í•´ì œ (scenes í´ë” ì•ˆì—)\n",
        "!unzip traintruck.zip -d data/scenes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1p-cJgegWkrh"
      },
      "source": [
        "# ì¥ë©´ í•™ìŠµ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdU5jeacMIyV"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# ==========================================\n",
        "# [ì„¤ì • ì˜ì—­] ì—¬ê¸°ë§Œ ìˆ˜ì •í•˜ë©´ ë©ë‹ˆë‹¤.\n",
        "# ==========================================\n",
        "\n",
        "# 1. ë°ì´í„°ê°€ ìˆëŠ” ìƒìœ„ í´ë” (scenes í´ë”)\n",
        "DATA_ROOT = \"/content/gaussian-splatting/data/scenes\"\n",
        "\n",
        "# 2. ê²°ê³¼ë¬¼ì„ ì €ì¥í•  í´ë”\n",
        "OUTPUT_ROOT = \"/content/gaussian-splatting/data/ckpts\"\n",
        "\n",
        "# 3. í•™ìŠµí•  ì¥ë©´ ë¦¬ìŠ¤íŠ¸ (8ê°œ)\n",
        "SCENES = [\n",
        "    \"bonsai\", \"counter\", \"bicycle\", \"train\",\n",
        "    \"garden\", \"stump\", \"kitchen\", \"truck\"\n",
        "]\n",
        "\n",
        "# 4. ì €ì¥í•  ì²´í¬í¬ì¸íŠ¸ Iteration (5ê°œ ì§€ì )\n",
        "# ì´ˆê¸°(7k), ì¤‘ê¸°(15k), í›„ê¸°(20k, 25k), ìˆ˜ë ´(30k)\n",
        "SAVE_ITERS = [7000, 15000, 20000, 25000, 30000]\n",
        "\n",
        "# 5. GPU í•´ìƒë„ ì˜µì…˜ (ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ 2 ë˜ëŠ” 4ë¡œ ë³€ê²½)\n",
        "RESOLUTION_SCALE = 4\n",
        "\n",
        "# 6. ìµœì¢… iteration (í•™ìŠµ ì™„ë£Œ ê¸°ì¤€)\n",
        "FINAL_ITER = 30000\n",
        "\n",
        "# ==========================================\n",
        "\n",
        "# ì €ì¥ ì˜µì…˜ì„ ë¬¸ìì—´ë¡œ ë³€í™˜\n",
        "save_iter_str = \" \".join(map(str, SAVE_ITERS))\n",
        "\n",
        "def is_training_complete(scene_name: str, model_path: str) -> bool:\n",
        "    \"\"\"Check if training is already complete for a scene.\"\"\"\n",
        "    final_ckpt = Path(model_path) / \"point_cloud\" / f\"iteration_{FINAL_ITER}\" / \"point_cloud.ply\"\n",
        "    return final_ckpt.exists()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRxpoSKXW1Vq"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(f\"ğŸš€ ì´ {len(SCENES)}ê°œ ì¥ë©´ì— ëŒ€í•œ ìˆœì°¨ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...\\n\")\n",
        "\n",
        "for idx, scene in enumerate(SCENES, 1):\n",
        "    source_path = os.path.join(DATA_ROOT, scene)\n",
        "    model_path = os.path.join(OUTPUT_ROOT, scene)\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"[{idx}/{len(SCENES)}] ì¥ë©´: {scene}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"  ë°ì´í„° ê²½ë¡œ: {source_path}\")\n",
        "    print(f\"  ì €ì¥ ê²½ë¡œ: {model_path}\")\n",
        "    \n",
        "    # í•™ìŠµ ì™„ë£Œ ì—¬ë¶€ í™•ì¸\n",
        "    if is_training_complete(scene, model_path):\n",
        "        print(f\"  â­ï¸  {scene}ëŠ” ì´ë¯¸ í•™ìŠµì´ ì™„ë£Œë˜ì–´ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
        "        continue\n",
        "    \n",
        "    # ì†ŒìŠ¤ ê²½ë¡œ ì¡´ì¬ í™•ì¸\n",
        "    if not os.path.exists(source_path):\n",
        "        print(f\"  âŒ ê²½ê³ : {source_path}ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
        "        continue\n",
        "    \n",
        "    # ëª…ë ¹ì–´ êµ¬ì„±\n",
        "    cmd = [\n",
        "        \"python\", \"train.py\",\n",
        "        \"-s\", source_path,\n",
        "        \"-m\", model_path,\n",
        "        \"-r\", str(RESOLUTION_SCALE),\n",
        "        \"--save_iterations\"\n",
        "    ] + list(map(str, SAVE_ITERS))\n",
        "    \n",
        "    # subprocessë¡œ ì‹¤í–‰ (ì—ëŸ¬ ì²˜ë¦¬ í¬í•¨)\n",
        "    try:\n",
        "        print(f\"  ğŸƒ í•™ìŠµ ì‹œì‘...\")\n",
        "        result = subprocess.run(\n",
        "            cmd,\n",
        "            check=True,\n",
        "            capture_output=False,  # ì‹¤ì‹œê°„ ë¡œê·¸ ì¶œë ¥\n",
        "            text=True\n",
        "        )\n",
        "        print(f\"  âœ… {scene} í•™ìŠµ ì™„ë£Œ!\")\n",
        "        \n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"  âŒ {scene} í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "        print(f\"  âš ï¸  ë‹¤ìŒ ì¥ë©´ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤...\")\n",
        "        continue\n",
        "    except Exception as e:\n",
        "        print(f\"  âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}\")\n",
        "        print(f\"  âš ï¸  ë‹¤ìŒ ì¥ë©´ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤...\")\n",
        "        continue\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"ğŸ‰ ëª¨ë“  ì¥ë©´ì˜ í•™ìŠµì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "print(f\"{'='*60}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# í†µê³„ì  íŠ¹ì§• ì¶”ì¶œ (Feature Extraction)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import gc\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import sys\n",
        "\n",
        "# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€\n",
        "sys.path.insert(0, '/content/gaussian-splatting')\n",
        "\n",
        "from src.gs_adapter import load_gaussians, Gaussians\n",
        "from src.features import eigen_stats, estimate_coverage_overlap\n",
        "from src.run_experiments import load_cameras_from_json, build_view_matrix, build_projection_matrix\n",
        "\n",
        "# GPU ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "print(\"âœ… í†µê³„ ë¶„ì„ ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_features_from_checkpoint(\n",
        "    scene_id: str,\n",
        "    ckpt_path: Path,\n",
        "    cameras_path: Path,\n",
        "    iteration: int\n",
        ") -> dict:\n",
        "    \"\"\"Extract statistical features from a single checkpoint.\"\"\"\n",
        "    \n",
        "    results = {\n",
        "        'scene_id': scene_id,\n",
        "        'iteration': iteration,\n",
        "        'N_g': 0,\n",
        "        'coverage': 0.0,\n",
        "        'mean_alpha': 0.0,\n",
        "        'energy_density': 0.0,\n",
        "        'anisotropy_median': 0.0,\n",
        "        'anisotropy_mean': 0.0,\n",
        "        'anisotropy_std': 0.0,\n",
        "        'volume_median': 0.0,\n",
        "        'psnr': None,  # Will be computed separately if possible\n",
        "    }\n",
        "    \n",
        "    try:\n",
        "        # Load Gaussians\n",
        "        gs = load_gaussians(ckpt_path, max_sh_degree=3)\n",
        "        N_g = gs.xyz.shape[0]\n",
        "        results['N_g'] = N_g\n",
        "        \n",
        "        # Compute geometric statistics\n",
        "        stats = eigen_stats(gs.scaling, gs.rotation)\n",
        "        anisotropy = stats['anisotropy'].cpu().numpy()\n",
        "        volume = stats['volume'].cpu().numpy()\n",
        "        \n",
        "        results['anisotropy_median'] = float(np.median(anisotropy))\n",
        "        results['anisotropy_mean'] = float(np.mean(anisotropy))\n",
        "        results['anisotropy_std'] = float(np.std(anisotropy))\n",
        "        results['volume_median'] = float(np.median(volume))\n",
        "        \n",
        "        # Load cameras and compute coverage/overlap for first camera (representative)\n",
        "        try:\n",
        "            cameras = load_cameras_from_json(cameras_path)\n",
        "            if len(cameras) > 0:\n",
        "                cam = cameras[0]\n",
        "                viewmat = build_view_matrix(\n",
        "                    cam.get('position', [0, 0, 0]),\n",
        "                    cam.get('rotation', [[1,0,0], [0,1,0], [0,0,1]])\n",
        "                )\n",
        "                projmat = build_projection_matrix(\n",
        "                    cam.get('fx', 400.0),\n",
        "                    cam.get('fy', 400.0),\n",
        "                    cam.get('width', 800),\n",
        "                    cam.get('height', 800)\n",
        "                )\n",
        "                \n",
        "                metrics = estimate_coverage_overlap(\n",
        "                    gs=gs,\n",
        "                    viewmat=viewmat,\n",
        "                    projmat=projmat,\n",
        "                    image_height=cam.get('height', 800),\n",
        "                    image_width=cam.get('width', 800),\n",
        "                    alpha_threshold=0.01,\n",
        "                    sh_degree=3\n",
        "                )\n",
        "                \n",
        "                results['coverage'] = metrics['coverage']\n",
        "                results['mean_alpha'] = metrics['mean_alpha']\n",
        "                results['energy_density'] = metrics['energy_density']\n",
        "        except Exception as e:\n",
        "            print(f\"    âš ï¸  Coverage ê³„ì‚° ì‹¤íŒ¨: {e}\")\n",
        "        \n",
        "        # Clean up\n",
        "        del gs, stats\n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"    âŒ íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨: {e}\")\n",
        "        return None\n",
        "    \n",
        "    return results\n",
        "\n",
        "print(\"âœ… íŠ¹ì§• ì¶”ì¶œ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ëª¨ë“  ì¥ë©´ê³¼ ì²´í¬í¬ì¸íŠ¸ì— ëŒ€í•´ í†µê³„ ì¶”ì¶œ\n",
        "all_results = []\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"ğŸ“Š í†µê³„ì  íŠ¹ì§• ì¶”ì¶œ ì‹œì‘\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "for scene in SCENES:\n",
        "    scene_model_path = Path(OUTPUT_ROOT) / scene\n",
        "    \n",
        "    # cameras.json ê²½ë¡œ í™•ì¸\n",
        "    cameras_path = scene_model_path / \"cameras.json\"\n",
        "    if not cameras_path.exists():\n",
        "        print(f\"âš ï¸  {scene}: cameras.jsonì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
        "        continue\n",
        "    \n",
        "    print(f\"\\nğŸ“ ì¥ë©´: {scene}\")\n",
        "    \n",
        "    # ê° ì²´í¬í¬ì¸íŠ¸ iterationì— ëŒ€í•´ ì²˜ë¦¬\n",
        "    for iteration in SAVE_ITERS:\n",
        "        ckpt_path = scene_model_path / \"point_cloud\" / f\"iteration_{iteration}\" / \"point_cloud.ply\"\n",
        "        \n",
        "        if not ckpt_path.exists():\n",
        "            print(f\"  â­ï¸  iteration_{iteration}: ì²´í¬í¬ì¸íŠ¸ ì—†ìŒ\")\n",
        "            continue\n",
        "        \n",
        "        print(f\"  ğŸ” iteration_{iteration} ë¶„ì„ ì¤‘...\")\n",
        "        \n",
        "        try:\n",
        "            result = extract_features_from_checkpoint(\n",
        "                scene_id=scene,\n",
        "                ckpt_path=ckpt_path,\n",
        "                cameras_path=cameras_path,\n",
        "                iteration=iteration\n",
        "            )\n",
        "            \n",
        "            if result is not None:\n",
        "                all_results.append(result)\n",
        "                print(f\"    âœ… ì™„ë£Œ: N_g={result['N_g']}, Coverage={result['coverage']:.4f}\")\n",
        "            else:\n",
        "                print(f\"    âŒ ì‹¤íŒ¨\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"    âŒ ì˜¤ë¥˜: {e}\")\n",
        "            continue\n",
        "        \n",
        "        # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "    \n",
        "    # ì¥ë©´ ì²˜ë¦¬ ì™„ë£Œ í›„ ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    print(f\"  âœ… {scene} ì²˜ë¦¬ ì™„ë£Œ\\n\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"ğŸ“Š ì´ {len(all_results)}ê°œ ì²´í¬í¬ì¸íŠ¸ ë¶„ì„ ì™„ë£Œ\")\n",
        "print(f\"{'='*60}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DataFrameìœ¼ë¡œ ë³€í™˜ ë° ì €ì¥\n",
        "if len(all_results) > 0:\n",
        "    df = pd.DataFrame(all_results)\n",
        "    \n",
        "    # ì»¬ëŸ¼ ìˆœì„œ ì •ë¦¬\n",
        "    column_order = [\n",
        "        'scene_id', 'iteration', 'N_g',\n",
        "        'coverage', 'mean_alpha', 'energy_density',\n",
        "        'anisotropy_median', 'anisotropy_mean', 'anisotropy_std',\n",
        "        'volume_median', 'psnr'\n",
        "    ]\n",
        "    df = df[[col for col in column_order if col in df.columns]]\n",
        "    \n",
        "    # ê²°ê³¼ ì €ì¥\n",
        "    output_csv = Path(OUTPUT_ROOT) / \"records.csv\"\n",
        "    df.to_csv(output_csv, index=False)\n",
        "    \n",
        "    print(f\"\\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_csv}\")\n",
        "    print(f\"\\nğŸ“ˆ ìš”ì•½ í†µê³„:\")\n",
        "    print(df.groupby('scene_id').agg({\n",
        "        'N_g': 'max',\n",
        "        'coverage': ['mean', 'max'],\n",
        "        'anisotropy_median': 'mean'\n",
        "    }))\n",
        "    \n",
        "    print(f\"\\nğŸ“Š ì „ì²´ ë°ì´í„°í”„ë ˆì„:\")\n",
        "    print(df)\n",
        "else:\n",
        "    print(\"âš ï¸  ì¶”ì¶œëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (ì„ íƒì‚¬í•­) PSNR ê³„ì‚°\n",
        "\n",
        "render.pyë¥¼ ì‚¬ìš©í•˜ì—¬ test setì— ëŒ€í•œ PSNRì„ ê³„ì‚°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PSNR ê³„ì‚° (ì„ íƒì‚¬í•­ - ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŒ)\n",
        "# ê° ì¥ë©´ì˜ ìµœì¢… iteration(30000)ì— ëŒ€í•´ì„œë§Œ PSNR ê³„ì‚°\n",
        "\n",
        "COMPUTE_PSNR = False  # Trueë¡œ ì„¤ì •í•˜ë©´ PSNR ê³„ì‚° ìˆ˜í–‰\n",
        "\n",
        "if COMPUTE_PSNR:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"ğŸ“¸ PSNR ê³„ì‚° ì‹œì‘ (ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "    \n",
        "    psnr_results = {}\n",
        "    \n",
        "    for scene in SCENES:\n",
        "        scene_model_path = Path(OUTPUT_ROOT) / scene\n",
        "        source_path = Path(DATA_ROOT) / scene\n",
        "        \n",
        "        if not scene_model_path.exists() or not source_path.exists():\n",
        "            continue\n",
        "        \n",
        "        print(f\"ğŸ“¸ {scene} ë Œë”ë§ ì¤‘...\")\n",
        "        \n",
        "        try:\n",
        "            # render.py ì‹¤í–‰ (test setë§Œ ë Œë”ë§)\n",
        "            cmd = [\n",
        "                \"python\", \"render.py\",\n",
        "                \"-s\", str(source_path),\n",
        "                \"-m\", str(scene_model_path),\n",
        "                \"--iteration\", \"30000\",\n",
        "                \"--skip_train\",  # train set ê±´ë„ˆë›°ê¸°\n",
        "                \"--quiet\"\n",
        "            ]\n",
        "            \n",
        "            result = subprocess.run(\n",
        "                cmd,\n",
        "                capture_output=True,\n",
        "                text=True,\n",
        "                timeout=3600  # 1ì‹œê°„ íƒ€ì„ì•„ì›ƒ\n",
        "            )\n",
        "            \n",
        "            # metrics.pyë¡œ PSNR ê³„ì‚°\n",
        "            metrics_cmd = [\n",
        "                \"python\", \"metrics.py\",\n",
        "                \"-m\", str(scene_model_path)\n",
        "            ]\n",
        "            \n",
        "            metrics_result = subprocess.run(\n",
        "                metrics_cmd,\n",
        "                capture_output=True,\n",
        "                text=True,\n",
        "                timeout=300\n",
        "            )\n",
        "            \n",
        "            # PSNR íŒŒì‹± (ê°„ë‹¨í•œ ë°©ë²•)\n",
        "            # ì‹¤ì œë¡œëŠ” metrics.pyì˜ ì¶œë ¥ì„ íŒŒì‹±í•´ì•¼ í•¨\n",
        "            print(f\"  âœ… {scene} ë Œë”ë§ ì™„ë£Œ\")\n",
        "            \n",
        "        except subprocess.TimeoutExpired:\n",
        "            print(f\"  â±ï¸  {scene} íƒ€ì„ì•„ì›ƒ\")\n",
        "        except Exception as e:\n",
        "            print(f\"  âŒ {scene} ì˜¤ë¥˜: {e}\")\n",
        "        \n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "    \n",
        "    print(\"\\nâœ… PSNR ê³„ì‚° ì™„ë£Œ\")\n",
        "else:\n",
        "    print(\"\\nâ­ï¸  PSNR ê³„ì‚° ê±´ë„ˆëœ€ (COMPUTE_PSNR=False)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# results.json NaN ë¬¸ì œ ì§„ë‹¨ ë° í•´ê²°\n",
        "\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"ğŸ” results.json NaN ë¬¸ì œ ì§„ë‹¨\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "for scene in SCENES:\n",
        "    scene_model_path = Path(OUTPUT_ROOT) / scene\n",
        "    results_json_path = scene_model_path / \"results.json\"\n",
        "    \n",
        "    if not results_json_path.exists():\n",
        "        print(f\"âš ï¸  {scene}: results.jsonì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        continue\n",
        "    \n",
        "    print(f\"\\nğŸ“ {scene} ì§„ë‹¨ ì¤‘...\")\n",
        "    \n",
        "    # results.json ì½ê¸°\n",
        "    with open(results_json_path, 'r') as f:\n",
        "        results_data = json.load(f)\n",
        "    \n",
        "    scene_key = str(scene_model_path)\n",
        "    if scene_key not in results_data:\n",
        "        print(f\"  âš ï¸  results.jsonì— {scene_key}ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        continue\n",
        "    \n",
        "    # ê° iteration í™•ì¸\n",
        "    for iteration in SAVE_ITERS:\n",
        "        method_key = f\"ours_{iteration}\"\n",
        "        \n",
        "        if method_key not in results_data[scene_key]:\n",
        "            print(f\"  âš ï¸  {scene} iteration_{iteration}: method '{method_key}'ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "            continue\n",
        "        \n",
        "        psnr_value = results_data[scene_key][method_key].get(\"PSNR\")\n",
        "        \n",
        "        if psnr_value is None or (isinstance(psnr_value, float) and (psnr_value != psnr_value)):  # NaN check\n",
        "            print(f\"\\n  ğŸ” {scene} iteration_{iteration} NaN ì›ì¸ í™•ì¸:\")\n",
        "            \n",
        "            # ë Œë”ë§ ê²°ê³¼ í´ë” í™•ì¸\n",
        "            renders_dir = scene_model_path / \"test\" / method_key / \"renders\"\n",
        "            gt_dir = scene_model_path / \"test\" / method_key / \"gt\"\n",
        "            \n",
        "            print(f\"    ğŸ“‚ ë Œë”ë§ í´ë”: {renders_dir}\")\n",
        "            print(f\"    ğŸ“‚ GT í´ë”: {gt_dir}\")\n",
        "            \n",
        "            renders_exist = renders_dir.exists()\n",
        "            gt_exist = gt_dir.exists()\n",
        "            \n",
        "            if not renders_exist:\n",
        "                print(f\"    âŒ ë Œë”ë§ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤!\")\n",
        "                print(f\"       í•´ê²°: render.pyë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
        "                continue\n",
        "            \n",
        "            if not gt_exist:\n",
        "                print(f\"    âŒ GT í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤!\")\n",
        "                print(f\"       í•´ê²°: render.pyë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
        "                continue\n",
        "            \n",
        "            # ì´ë¯¸ì§€ íŒŒì¼ í™•ì¸\n",
        "            render_files = list(renders_dir.glob(\"*.png\")) if renders_dir.exists() else []\n",
        "            gt_files = list(gt_dir.glob(\"*.png\")) if gt_dir.exists() else []\n",
        "            \n",
        "            print(f\"    ğŸ“Š ë Œë”ë§ ì´ë¯¸ì§€ ê°œìˆ˜: {len(render_files)}\")\n",
        "            print(f\"    ğŸ“Š GT ì´ë¯¸ì§€ ê°œìˆ˜: {len(gt_files)}\")\n",
        "            \n",
        "            if len(render_files) == 0:\n",
        "                print(f\"    âŒ ë Œë”ë§ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤!\")\n",
        "                print(f\"       í•´ê²°: render.pyë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
        "                continue\n",
        "            \n",
        "            if len(gt_files) == 0:\n",
        "                print(f\"    âŒ GT ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤!\")\n",
        "                print(f\"       í•´ê²°: render.pyë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
        "                continue\n",
        "            \n",
        "            if len(render_files) != len(gt_files):\n",
        "                print(f\"    âš ï¸  ì´ë¯¸ì§€ ê°œìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!\")\n",
        "                print(f\"       ë Œë”ë§: {len(render_files)}ê°œ, GT: {len(gt_files)}ê°œ\")\n",
        "                print(f\"       í•´ê²°: render.pyë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
        "                continue\n",
        "            \n",
        "            # íŒŒì¼ëª… ë§¤ì¹­ í™•ì¸\n",
        "            render_names = {f.stem for f in render_files}\n",
        "            gt_names = {f.stem for f in gt_files}\n",
        "            \n",
        "            if render_names != gt_names:\n",
        "                print(f\"    âš ï¸  íŒŒì¼ëª…ì´ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!\")\n",
        "                print(f\"       ë Œë”ë§ì—ë§Œ ìˆëŠ” íŒŒì¼: {render_names - gt_names}\")\n",
        "                print(f\"       GTì—ë§Œ ìˆëŠ” íŒŒì¼: {gt_names - render_names}\")\n",
        "                print(f\"       í•´ê²°: render.pyë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
        "                continue\n",
        "            \n",
        "            print(f\"    âœ… í´ë”ì™€ ì´ë¯¸ì§€ëŠ” ì •ìƒì…ë‹ˆë‹¤.\")\n",
        "            print(f\"    âš ï¸  metrics.py ê³„ì‚°ì— ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
        "            print(f\"       í•´ê²°: metrics.pyë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
        "            \n",
        "            # ìˆ˜ë™ìœ¼ë¡œ metrics.py ì¬ì‹¤í–‰ ì œì•ˆ\n",
        "            print(f\"\\n    ğŸ’¡ ìˆ˜ë™ ì¬ì‹¤í–‰:\")\n",
        "            print(f\"       python metrics.py -m {scene_model_path}\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"âœ… ì§„ë‹¨ ì™„ë£Œ\")\n",
        "print(f\"{'='*60}\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "h1OlN_5NWWXq"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
